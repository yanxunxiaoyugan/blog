1. 

   > 匿名用户 提问：
   >
   > 秦老师，请问不要 redis 等缓存服务器，多加几个 MYSQL 只读从库，这样就不需要维护缓存与数据库的数据一致性，这样可行吗？
   >
   > 缓存和从库，解决的问题，有一部分重叠，但不完全一致。 从库：读压力，特别是一些分析、报表类的查询需求。 缓存：除了原始数据库数据，还可以缓存中间处理数据，service方法处理结果，session共享信息等。

2. 

   > felix徐 提问：
   >
   > 老师好：    在第二十课讲到的微服务架构最佳实践06中有提到业务监控和系统监控等监控系统，能否详细说说业务监控如何实现的吗？比如用什么方案和工具 要监控哪些指标？可以的话把其他几个监控和告警都用到了什么工具中间件或者方案 也说一说呗？
   >
   > 系统监控大家都知道怎么回事儿了。我们说说业务监控。 为什么要做业务监控：因为技术指标往往跟业务指标并不匹配。 系统里，我们可以统计一下关键的业务方法调用，做计数，做汇总等等。 这些就可以把业务的很多指标通过类似APM探针的方式收集起来。 如果没有这些技术，也可以通过手工埋点的方式做。 你可以了解一下可观测性的metrics。 常见的方式下，我们可以用业务埋点+promethus+grafana来实现监控。 商业产品也很多，比如我们之前用的datadog，功能非常强大。 国内很多做apm的公司也有商业产品，比如听云的业务监控就做的很不错。

3. 

   > 雨天 提问：
   >
   > 老师您好，监控告警时 CPU，内存，I/O等参数怎么设置？如计算密集型 CPU设置百分之多少合适？ 计算节点如果可以自动伸缩的话是不是应该设置比较高？ 存储节点（如mysql）是不是就要设置低些？ 设置这些参数后面的方法论是什么？
   >
   > 实际上，我并没有合理的数值告诉你。 先问一下，你监控这些指标的目的是什么？ 基于这些目的，就可以反过来凭经验去定一个指标，然后不断根据实际情况去优化它。 举例来说，我们线上清算系统，我发现过去一段时间业务稳定的情况下，cpu使用率都在25-35%之间，那么我现在可以先假设，cpu超过50%的时候，清算压力就非常大了，有可能有问题。超过80%的时候，有可能就处理不过来了。我就先做一个50%的报警，80%的报警。 然后运行一段时间，发现超过45%的时候，一般就处理很慢了，拿就可以加一个45的。等系统优化好了，可能稳稳的跑在50的线上，我就可以把最低水位的报警设置在60以上了。 如何设置，跟业务有直接关系，跟计算还是存储一般有关系，但不绝对。我也见过很多人长期把mysql的cpu基本跑满的。

4. >
   >
   >2期同学：如果数据源的数据更新,怎么去更新缓存?是更新数据源,然后删除缓存?有什么方法能尽量避免读取到旧数据？ KK：其实我们不好定义旧数据和新数据。 数据库正在进行更新操作，那么现在缓存的数据是旧的还是新的？ 说是旧的，对同时也不对。因为数据库更新还没完成，这时候直接读就数据库其实也是缓存里的这个数据。 数据库和缓存，作为两个独立的服务器。 没有任何办法能保证不影响业务不停顿的情况下，恰好“同时”更新数据源和缓存。 如果想要严格做到不读旧数据，只有串行化“缓存+数据库”，更新数据库的时候，缓存直接不允许读了，用全局锁卡死，更新完数据库，更新缓存，然后才把读的流量放进来。

5. > 曾同学：请教大家一个问题呀 在Java线程池里面，当提交的任务数大于核心线程数时，为什么是先添加队列而不是先创建最大线程数呢？ KK：我在课上讲过这个问题。 默认核心线程数一般是cpu核心数，也就是说：如果任务都是计算密集型的情况下，在所有核心线程都在忙的时候，又有任务添加进来，这时候加新线程并没有什么卵用。所以，先缓冲到队列里来是个比直接添加线程更好的策略。 1、如果前面的任务处理的比较快，那么在新创建线程的时间里，有可能前面的核心线程有的就完成了，可以释放出来做后面加入的任务。 2、如果队列里缓冲了很多任务，前面的任务还是没有处理完，有可能当前的任务是IO密集型的，这时候再考虑新增线程，能够最大限度的使用系统CPU资源。 钱同学：IO密集型和CPU密集型的选择，tomcat的线程池就是你说的，先开线程后入队，因为tomcat是io密集，如果你的代码里面，一旦涉及数据库，db，task这些，基本上都是io密集。如果你刻意做了全异步，那就是io不密集 曾同学：现在大部分的系统基本上都是io密集型的任务吧，这种类型的任务占多数 KK：系统是io密集的，线程池处理的任务可不一定。 只要你能确定使用方式，先开线程也合理。 就像是，xmx/xms很多时候我们配置一致，List/Map我们建议指定初始容量。 都是一个道理，使用者知道自己的应用/业务处理对应的特性。 但是线程池，堆内存，集合类，作为一个基础设施，必须同时支持不同场景，在假设不知道业务数据特性的情况下，给出一个通用方案。

6. > lovebug 提问：
   >
   > 秦老师，面试的时候被问到，能给公司带来什么价值？这个问题要怎么回答。（新人）
   >
   > ![img](https://images.zsxq.com/Fkf_fx4b1n5n99O3lwV4_0eu_kzB?imageMogr2/auto-orient/thumbnail/540x/format/jpg/blur/1x0/quality/75&e=1622476799&token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:It1YKLrcr54NDWfM5wIjrq9HQMU=)
   >
   > 这是送分题。标准答案，把自己往死里吹。 我之前的xxx方面的经验，能增强咱们团队对于xxx方向的能力。 我个人对ABC技术深入的研究，能提升咱们团队甚至公司的技术积累。 我对yyy方法有多年思考，能提升咱们研发的效率，以及项目/代码质量。 我在技术圈有大把的人脉，对于咱们技术招聘，团队组件，技术和方案交流，，，，等都会有很多积极的影响。 ...... 好好去总结，属于你自己的优势。

7. > 小马的学生：请问现在数据库分库分表用的多方案有哪些？最近看了下shardingsphere，感觉文档好像有不少坑。一般这种是自己实现还是用第三方工具呢？ KK：作为ShardingSphere的PMC，我来强答一波：用的非常多。首先，现在很多中小公司用的阿里云RDS和DRDS，都是基于MySQL分库分表/TDDL做的。 其次，目前我见到的几乎所有1-2线公司，甚至一些互联网的新兴创新公司，都用了数据库分库分表或者自己造轮子的框架和中间件。 第三，我目前在给各种大型金融机构做核心业务的分布式改造相关工作，国内大型金融机构也都在开始用ShardingSphere。 第四，ShardingSphere发源于当当，成熟与京东，京东的核心金融业务，白条的千亿级别数据量，都是sharding-jdbc支撑的。 第五，数据库中间件，跟其他中间件不太一样，它涉及到数据的一致性，对整个业务系统最后最底层的正确性保障。自己如果没有相关积累，造轮子，要走很多弯路，我可以负责任的说，一定没有ShardingSphere稳定可靠。

8. > 求知者 提问：
   >
   > 秦老师好，设计数据库时，如果多个业务字段具有唯一性约束，主键一般用自增id好，还是用多个业务字段做联合主键好呢？这种一般从哪些方面做考虑？一般最佳实践是怎样的呢？
   >
   > 按照目前的一般数据库设计规范，是不允许多个列做联合主键的。 我们会使用id(int/bigint)做主键，这样数据在流转和传递过程只需传递这样一个int或long即可，需要的时候，再去拿实际数据。 同样的，我们可以在表上家一个唯一约束，这样的话，会自动加这几个键的组合索引，方便我们保证业务唯一，以及按这几个业务条件查询时的性能。 当然，也有一些互联网高并发业务，同时对一致性要求不那么高，唯一约束也会去掉，这样可以把唯一约束的判断，放到业务代码，从而简化数据库这一块的处理。

9. > 小马的学生：请问现在数据库分库分表用的多方案有哪些？最近看了下shardingsphere，感觉文档好像有不少坑。一般这种是自己实现还是用第三方工具呢？ KK：作为ShardingSphere的PMC，我来强答一波：用的非常多。首先，现在很多中小公司用的阿里云RDS和DRDS，都是基于MySQL分库分表/TDDL做的。 其次，目前我见到的几乎所有1-2线公司，甚至一些互联网的新兴创新公司，都用了数据库分库分表或者自己造轮子的框架和中间件。

10. > 求知者 提问：
    >
    > 秦老师好，设计数据库时，如果多个业务字段具有唯一性约束，主键一般用自增id好，还是用多个业务字段做联合主键好呢？这种一般从哪些方面做考虑？一般最佳实践是怎样的呢？
    >
    > 按照目前的一般数据库设计规范，是不允许多个列做联合主键的。 我们会使用id(int/bigint)做主键，这样数据在流转和传递过程只需传递这样一个int或long即可，需要的时候，再去拿实际数据。 同样的，我们可以在表上家一个唯一约束，这样的话，会自动加这几个键的组合索引，方便我们保证业务唯一，以及按这几个业务条件查询时的性能。 当然，也有一些互联网高并发业务，同时对一致性要求不那么高，唯一约束也会去掉，这样可以把唯一约束的判断，放到业务代码，从而简化数据库这一块的处理。

11. > 匿名用户 提问：
    >
    > 请问秦老师，架构师面试，如何体现出架构能力？
    >
    > 这个问题很大很虚，如果不进一步细化具体，根本无从回答。 我们现在一般认为架构师分以下几种： 1、企业架构师，掌握企业整体的IT架构，把握方向，有点CIO的方向了。 2、业务架构师，现在我们意识到架构内部也分为业务架构和IT架构，IT架构又包括应用架构、数据架构、技术架构。 3、系统架构师，偏应用架构。 4、软件架构师，偏技术，带点业务，了解应用，支持团队的项目开发。。。 其中软件架构师，应该是大家一般意义上说的。 1、所以，面试时，先反问面试官几个问题，框定到软件架构。 明确到是软件内的，项目组内的架构师。 2、然后说清楚你作为架构师，对项目的业务把握，模块分解，应用组件设计，通信机制，数据交互模式，技术选型的考虑，数据量和性能的评估，功能性需求和非功能性需求的处理。总之，在项目开发之前，把各种基础问题，影响工程化开发推进的问题，都想到，保证快速推进。 3、把你的架构设计，形成合适的产物输出，包括文档和架构图，流程图等。给团队内宣讲，给配合的其他团队讲清楚，推动大家一起按你的架构往前走。当团队内外因为配合、边界、技术点问题而争论时，通过自己的技术能力和影响力，敲定事情落地。 4、制定技术规范和质量标准，协调技术方案评审，code review，跟其他团队的技术讨论和交互。指导团队日常的开发和技术工作，搞定技术问题，充当指导员和消防队。 5、搞好团队的技术氛围，如果能再培养兄弟们的技术能力，更好了。 这一块，能聊的有很多，但是每个面试官自己的思考点以及经历可能不一样，这就需要通过对话引导到，他感兴趣的环节去深入讨论。

12. > **涛 提问：
    >
    > 秦老师，有新旧两个车联网平台（TSP），车端tbox连接TSP平台并上报或者接收下行数据，TSP端使用MQTT作为消息代理。两个平台分布在不同的私有idc机房，只能通过公网通讯。现在想让tbox平滑连接到新平台，由于某些原因tbox没法ota修改连接平台的地址，所以只能在平台端想办法，比如在旧平台配置tcp转发，将指定端口的流量转发到新平台，但是这样相当于一刀切，没法小批量试验。之前老师在群里提到了tcpcopy，我大概看了下它的三种架构，实际上它是copy的上行流量，对于平台端发出来的数据最终会丢弃，没法建立真正的双工通道（相当于旁路分支）。想问下是否有平滑迁移的可能？
    >
    > 不做tcp转发，直接用一个mqtt代理转发

13. > qi德隆东墙 提问：
    >
    > 老师，一般对象和一维数组的对象头有什么区别呢？ 还有就是，int[128][2]为什么占了3600个字节，可以列一个算式吗？
    >
    > 事实上，我们通过jmap -histo看到的只有一层对象占用的空间。而多维数组是多层（二维数组可以看做是一堆一维数组组成的）。 但是我们可以通过JOL工具查看。先添加引用： <dependency>    <groupId>org.openjdk.jol</groupId>    <artifactId>jol-core</artifactId>    <version>0.9</version> </dependency> 然后编写代码： public class TestMem {    public static void main(String[] args) {        int[] arr1 = new int[256];        int[][] arr2 = new int[128][2];        int[][][] arr3 = new int[64][2][2];        print("size : " + GraphLayout.parseInstance(arr1).totalSize());        print(ClassLayout.parseInstance(arr1).toPrintable());        print("size : " + GraphLayout.parseInstance(arr2).totalSize());        print(ClassLayout.parseInstance(arr2).toPrintable());        print("size : " + GraphLayout.parseInstance(arr3).totalSize());        print(ClassLayout.parseInstance(arr3).toPrintable());        System.out.println();    }    static void print(String message) {        System.out.println(message);        System.out.println("-------------------------");    } 运行查看结果： size : 1040 ------------------------- [I object internals: OFFSET SIZE TYPE DESCRIPTION        VALUE  0  4  (object header)       01 7b de 5e (00000001 01111011 11011110 01011110) (1591638785)  4  4  (object header)       08 00 00 00 (00001000 00000000 00000000 00000000) (8)  8  4  (object header)       6d 01 00 f8 (01101101 00000001 00000000 11111000) (-134217363)  12  4  (object header)       00 01 00 00 (00000000 00000001 00000000 00000000) (256)  16 1024 int [I.<elements>        N/A Instance size: 1040 bytes Space losses: 0 bytes internal + 0 bytes external = 0 bytes total ------------------------- size : 3072 ------------------------- [[I object internals: OFFSET SIZE TYPE DESCRIPTION        VALUE  0  4  (object header)       01 00 00 00 (00000001 00000000 00000000 00000000) (1)  4  4  (object header)       00 00 00 00 (00000000 00000000 00000000 00000000) (0)  8  4  (object header)       9f a4 00 f8 (10011111 10100100 00000000 11111000) (-134175585)  12  4  (object header)       80 00 00 00 (10000000 00000000 00000000 00000000) (128)  16 512  [I [[I.<elements>       N/A Instance size: 528 bytes Space losses: 0 bytes internal + 0 bytes external = 0 bytes total ------------------------- size : 4608 ------------------------- [[[I object internals: OFFSET SIZE TYPE DESCRIPTION        VALUE  0  4  (object header)       01 00 00 00 (00000001 00000000 00000000 00000000) (1)  4  4  (object header)       00 00 00 00 (00000000 00000000 00000000 00000000) (0)  8  4  (object header)       8f a5 00 f8 (10001111 10100101 00000000 11111000) (-134175345)  12  4  (object header)       40 00 00 00 (01000000 00000000 00000000 00000000) (64)  16 256 [[I [[[I.<elements>       N/A Instance size: 272 bytes Space losses: 0 bytes internal + 0 bytes external = 0 bytes total ------------------------- 可以看到， 1、int[256];        => 内部=第一层1040 2、int[128][2];     => 内部3072，第一层528 ==> 3600 3、int[64][2][2];  => 内部4608，第一层272  ==> 4880 对于int[256]，数组本身是个对象占16，每个子对象指针一个int，256个int=256*4=1024，所以一共是16+1024=1040； 对于int[128][2]，二维数组本身16，第一层是128*4=512，一共是528. 事实上，我们可以用print(GraphLayout.parseInstance(arr2).toPrintable()); 把二维数组里的一维数组集合打印出来： [I@27082746d, [I@66133adcd, [I@7bfcd12cd, [I@42f30e0ad, ...   ADDRESS  SIZE TYPE PATH       VALUE   76acd9858   24 [I <r1>       [0, 0]   76acd9870   24 [I <r2>       [0, 0]   76acd9888   24 [I <r3>       [0, 0]   76acd98a0   24 [I <r4>       [0, 0]    。。。。。。 可以看到，每个二维的位置，都是一个一维的数组对象，长度为2， 所以每一个占用了一个对象头加上两个int，共16+4+4=24字节。 所以这一部分一共是24*128=3072字节。 同理，三维数组内部结构是二维数组： ADDRESS  SIZE TYPE PATH       VALUE   76acda728   24 [[I <r1>       [[0, 0], [0, 0]]   76acda740   24 [I <r1>[0]      [0, 0]   76acda758   24 [I <r1>[1]      [0, 0]   76acda770   24 [[I <r2>       [[0, 0], [0, 0]]   76acda788   24 [I <r2>[0]      [0, 0]   76acda7a0   24 [I <r2>[1]      [0, 0]   。。。。。。 这样的话，int[64][2][2]就比int[128][2]，多了一层也就是64个二维数组对象，他们占用64*24=1536字节。 所以三维数组内部使用内存为3072+1536=4608字节。

14. > \+ - x ÷ 提问：
    >
    > 老师好！我们系统会被公司内其他系统写的脚本大批量地调用，导致频繁查数据库，影响正常的用户操作。但是又不能禁掉这些调用。 现在我设想的方案是：将可能的热点数据放入redis中。        因为大批量调用是自动的，一页一页地查询，有多少页查多少页。很多数据结果的页数超过上千页。而正常用户是比较精确地查询，一般查询页数就几页。所以，设想，根据查询的页数，当超过10页时，即判定可能是脚本自动调的，在返回数据时，异步去查询后面20页的数据，将其存入redis缓存。后面再调用时，先查缓存。当缓存页数快被查完，再从数据库取数，放入缓存。        不知是否有更好的方案可以借鉴下，感谢！
    >
    > 单独提供一个接口给批量查询用，走从库

15. > 陈宏 提问：
    >
    > 支付交易双方如何做对账，有哪些要注意的地方？以前面蚂蚁金服时候问了个面试题：如果一天的交易明细特别大，到了t级别的，而网络带宽有限，如何优化？由于对对账业务不熟悉，只想到压缩后传过去。不知老师有啥优化方法？
    >
    > 分片来对，，对于每一片，对一个总的。 很多时候，如果总的数目和金额都对上了，就不对明细了。 如果对不上，再对明细，就可以节省很多带宽了。

16. > 2期同学：为什么最终标记以后，可以并发的删除不被引用的对象？他们不会在并发执行的线程里重新引用吗？ KK：不会。一个对象一旦没有任何对象引用它，那么在所有人看来，它已经消失了。虽然它还占据了一块堆内存，但是没有用了。它没法被复用，也没有办法再被其他人引用或调用。所以，这一块内存就变成了垃圾，必须要删除掉，释放内存。

17. > 2期同学：课程里用到的GCLogAnalysis里，“我们用数组来随机存放一部分生成的对象，这样可以模拟让一部分对象晋升到老年代”。对这段话不是太理解~想听听各位的见解？ KK：视频里说过哈。 这个方法里，可以看做两个作用域，一个是循环外面，一个循环内部。 这个cache[2000]定义在循环外面，随机生成的对象在循环里面。 所以循环处理这个过程中，大部分对象在下一次循环处理的时候，作用范围就失效了，没有人引用它了，可以被回收。 少量对象，有一定概率可以被放到循环外定义的cache数组，那么这些放到外层数组里的对象，在没有被其他对象替换掉之前，对它的引用存在，就不会被回收，从而有机会晋升到老年代。

18. > 匿名用户 提问：
    >
    > 我是2期学员，问个问题，是每启动一个JAVA程序都会起一个新的JVM吗
    >
    > 是

19. > 
    > 匿名 提问：
    >
    > 秦大哥您好，订单业务中金额的类型用什么呢？decimal是最优选择吗？
    >
    > 大部分情况下可以用。 对于精度有要求的，我们经常用bigint，加精度字段，两个咧表示。 比如12345，-10，表示0.0000012345

20. > 静晓晨曦 提问：
    >
    > ToB 多租户系统 数据库设计 目前初步理的需求 一个用户，可能是国内或者海外用户(可能没手机)，可以用手机号或邮箱登录，目前想的是国内用手机、国外用邮箱，涉及到账号查询，怎么存 这个用户可以同时属于多个企业，但多个企业的权限树可能不一致，用户可以一次登录后选择企业进入，然后分别有不同的权限 多个企业之间怎么隔离，涉及到审批流之类的，每个企业可以自定义自己相应权限的审批流路径
    >
    > 解决办法很多。 比如入口分国内版和国外版，登录后换成用户id流转就没区别了。 一个用户属于多个企业有两张常规操作。一是不同企业有各自入口比如特定子域名，类似企业邮箱。二是用户进去先选自己对应的多个企业中的某一个，类似企业微信。 最后一个不同企业不同流程就是常规多租户设计了。数据逻辑隔离加分片就成。

21. > 2期同学：怎么理解延迟和吞吐量的关系？为什么老师说高延迟吞吐量可能也会高（分布式系统），低延迟也可能吞吐量变低（GC和JVM）？ KK： 1、对于分布式系统，关于微服务对性能的影响。 大家可以先思考2个问题：延迟（latency）和吞吐量（throughout）有什么关系？ 延迟是响应时间么？ 先说一下延迟和响应时间，延迟是对于服务本身来说的，响应时间是相当于调用者来说的（更多的内容可以参考《[数据密集型应用系统设计](https://wx.zsxq.com/mweb/views/weread/search.html?keyword=数据密集型应用系统设计)》一书）： 延迟（latency） = 请求响应出入系统的时间 响应时间（ResponseTime）= 客户端请求开始，一直到收到响应的时间 = 延迟 + 网络耗时 理想状态下，延迟越低，吞吐越高，当然这是对单机单线程而言的，在分布式下就不成立了，举个反例： 比如从密云水库，拉一个水管到国贸，水流到国贸，需要1小时；如果再拉一个水管到顺义，20分钟就可以。如果你在国贸用水龙头接水，你可以单位时间接到非常多的水，这个数量跟你在过国贸还是顺义，没有关系，只跟水库单位时间输入的水量/水压有关系。但是如果你在水管里放一个小球，它从密云到国贸的时间是到顺义的时间的三倍，这样对于到国贸的这个水管系统，延迟很高，但是系统的吞吐量跟到顺义的是一样的。 同理，如果一个单体系统，被拆分成了10个服务，假如一个业务处理流程要经过5个服务，这5个服务只要是每个吞吐量（TPS/QPS）不低于原先的单体，那么整个微服务系统的吞吐量是不变的。相反地，我们通过服务变小，关系变简单，数据库简化，事务变小等等，如果5个系统的吞吐都比原来的系统打，那么改造后的系统，整体的吞吐也比之前要高。 那么这个过程的副作用是什么呢？简单的说，就是延迟变高了，原来都是本地调用，现在变成了5次远程调用，假设每次调用的网络延迟在1-10毫秒（物理机房+万兆网卡可以很低，云环境下比较高），那么延迟就会比之前增加增加5-50毫秒，而且前提是分布式下的请求，使用异步非阻塞的流式或消息处理方式，同步阻塞会更高，而且影响吞吐量。 好在低延迟的系统要求比较少见，对于一般的业务系统来说，可以水平扩展的能力比延迟增加几毫秒要重要的多。比如我们在淘宝或者京东，买个衣服，交易步骤的处理，在秒级都是可以接受的，如果是机票、酒店、电影票之类的，分钟级以上都是可以接受的。 再举一个现实的例子，某个公司从2016年起，就在做微服务改造，研发团队规模不大，业务发展很快，基础设施没有跟上，自动化测试、部署都没有。同时这个公司的主要核心业务是一个低延迟高并发的交易系统，微服务拆分导致系统的延迟进一步增大，客户满意度下降。很快研发团队就发现了拆分成了多个小系统以后，比单体更难以维护，继而采取了措施，把部分微服务进行合并，提高可维护性和控制延迟水平。 具体可以参考：[微服务架构深度解析与最佳实践 - 第五部分：七个应对策略之性能、一致性与高可用_KimmKing的技...](https://kimmking.blog.csdn.net/article/details/105775006) 2、上面说的是分布式的情况，对于GC和JVM，更简单。 也就是说每次处理一部分垃圾，并且大部分处理垃圾的时候，业务线程没停，只有少量线程做垃圾处理，这时候业务是不需要暂停的。 单位时间内业务系统创建的对象是一定的，为了低延迟，实际上没有马力全开的跑GC，也没有马力全开的跑业务线程，自然没有资源全开的Parallel GC对处理垃圾更高效率。 以打扫卫生为例，一层楼有很多工作人员在工作，现在需要打扫卫生。 1、串行GC：所有人都出去，一个保洁阿姨来打扫卫生，打扫完了，大家再进来工作。 2、并行GC：所有人都出来，一大群保洁阿姨来打扫卫生，打扫完了，大家再进来工作。 3、CMS：每次1/4的人出去，进来三五个阿姨打扫卫生，然后还有3/4的工作人员在干活，所以能够做到业务大部分时候不会被GC暂停（只需要在开始清点垃圾和确认垃圾的时候需要所有人暂停一小下）。但是明显的是，干活的阿姨变少了，所以整体处理效率实际上降低了。 4、G1：在CMS的基础上，把整个楼层的工位区域分成很多小片，每次处理其中的一部分片，所以可以更加精细化管理了，对每次作业的估计可以更加精确了，每次也是少量几个阿姨来打扫，所以效率其实也不会比Parallel高。

22. > 天地 提问：
    >
    > 老师，spring 类的方法里使用this调用内部方法 不走aop  怎么解决啊
    >
    > 这个问题之前讨论过，this.method() 是实际的调用类，不是代理类，所以自然不被AOP管理。 解决办法，直接在调用bean代码的地方显式调用method方法，这时候调用的是代理类，这里面有对method方法的包装增强，才会处理注解和AOP。
    >
    > 
    >
    > 查看详情
    >
    > Jenkins：之前代码里见过在当前类getBean方法拿到的对象是可以走AOP，当时不知道为什么，后来看了AOP的源码才明白，原来spring容器维护的是代理增强的实例